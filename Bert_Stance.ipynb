{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert Stance.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCpvgG0vwXAZ",
        "colab_type": "text"
      },
      "source": [
        "#Predicting Movie Review Sentiment with BERT on TF Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsZvic2YxnTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jviywGyWyKsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bert-tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhbGEfwgdEtw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "US_EAnICvP7f",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "# Optionally, set a GCP bucket location\n",
        "\n",
        "OUTPUT_DIR = 'out'#@param {type:\"string\"}\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\n",
        "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\n",
        "USE_BUCKET = False #@param {type:\"boolean\"}\n",
        "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\n",
        "\n",
        "if USE_BUCKET:\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\n",
        "  from google.colab import auth\n",
        "  auth.authenticate_user()\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    # Doesn't matter if the directory didn't exist\n",
        "    pass\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmLom7oItORj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Dragonet95/utils/raw/master/train_bodies.csv\n",
        "!wget https://github.com/Dragonet95/utils/raw/master/train_stances.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLP_GCebsj21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, dirname\n",
        "import re\n",
        "\n",
        "\n",
        "_COL_1 = ['Headline', 'Body ID', 'Stance']\n",
        "_COL_2 = ['Body ID', 'articleBody']\n",
        "_COL_3 = ['Headline', 'Body ID', 'Stance', 'articleBody']\n",
        "\n",
        "\n",
        "link = pd.read_csv(\"./train_stances.csv\", index_col=None, names=_COL_1, sep=',')\n",
        "bodies = pd.read_csv(\"./train_bodies.csv\", index_col=None, names=_COL_2, sep=',')\n",
        "\n",
        "link.Stance[link.Stance=='agree'] = \"1\"\n",
        "link.Stance[link.Stance=='disagree'] = \"2\"\n",
        "link.Stance[link.Stance=='discuss'] = \"0\"\n",
        "link.Stance[link.Stance=='unrelated'] = \"-1\"\n",
        "\n",
        "link = link[1:]\n",
        "bodies = bodies [1:]\n",
        "\n",
        "complete = link.merge(bodies, on='Body ID')\n",
        "complete = complete[1:]\n",
        "complete.info()\n",
        "\n",
        "complete.to_csv(\"stance.csv\", sep=',', encoding='utf-8', index=False)\n",
        "\n",
        "complete = complete.sample(frac=1).reset_index(drop=True)\n",
        "complete.info()\n",
        "\n",
        "train_df = complete[:40000]\n",
        "test_df = complete[40000:]\n",
        "\n",
        "with open(\"stance.pickle\", \"wb\") as f:\n",
        "    pickle.dump([train_df, test_df], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a-1Em8AXr_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import join, dirname\n",
        "import re\n",
        "\n",
        "\n",
        "_COL_1 = ['id', 'label', 'statement','subject','speaker','speakertitle','state','aff','c1','c2','c3','c4','c5']\n",
        "\n",
        "\n",
        "train = pd.read_csv(\"./train.tsv\", index_col=False, names=_COL_1, sep='\\t')\n",
        "test = pd.read_csv(\"./test.tsv\", index_col=False, names=_COL_1, sep='\\t')\n",
        "valid = pd.read_csv(\"./valid.tsv\", index_col=False, names=_COL_1, sep='\\t')\n",
        "\n",
        "\n",
        "train.info()\n",
        "test.info()\n",
        "valid.info()\n",
        "\n",
        "part = train.append(test)\n",
        "complete = part.append(valid)\n",
        "complete.info()\n",
        "\n",
        "complete2 = complete[['statement','label']]\n",
        "complete2.info()\n",
        "print(complete2)\n",
        "\n",
        "\n",
        "complete2.to_csv(\"politifactfull.csv\", sep='\\t', encoding='utf-8')\n",
        "\n",
        "train_df = complete[:10000]\n",
        "test_df = complete[10000:]\n",
        "\n",
        "with open(\"politifactfull.pickle\", \"wb\") as f:\n",
        "    pickle.dump([train_df, test_df], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reeKN3r0ozvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pandas --upgrade"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZjFwzaLoOc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Dragonet95/utils/raw/master/testtask2t.pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-I3S4I-NQLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Dragonet95/utils/raw/master/testtask2eng.pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MjMGubP5EJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Dragonet95/utils/raw/master/task2treng2000.pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "647thvINEzHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Dragonet95/utils/raw/master/stancetask2.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUufOIjoUyP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Dragonet95/utils/raw/master/politi.pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuws9GmFZIgl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/Dragonet95/utils/raw/master/train.tsv\n",
        "!wget https://github.com/Dragonet95/utils/raw/master/test.tsv\n",
        "!wget https://github.com/Dragonet95/utils/raw/master/valid.tsv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmFYvkylMwXn",
        "colab_type": "text"
      },
      "source": [
        "#Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC_w8SRqN0fr",
        "colab_type": "text"
      },
      "source": [
        "First, let's download the dataset, hosted by Stanford. The code below, which downloads, extracts, and imports the IMDB Large Movie Review Dataset, is borrowed from [this Tensorflow tutorial](https://www.tensorflow.org/hub/tutorials/text_classification_with_tf_hub)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fom_ff20gyy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import pandas\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  with open(\"stance.pickle\", 'rb') as f:\n",
        "    train_df, test_df = pickle.load(f)\n",
        "  \n",
        "  return train_df, test_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcHEeW5hoWVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import pandas\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  with open(\"task2treng2000.pickle\", 'rb') as f:\n",
        "    train_df, test_df = pickle.load(f)\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCElmj0gWfua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import pandas\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  with open(\"testtask2t.pickle\", 'rb') as f:\n",
        "    train_df, test_df = pickle.load(f)\n",
        "  \n",
        "  return train_df, test_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgiQlD5uU1Sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import pandas\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  with open(\"politi.pickle\", 'rb') as f:\n",
        "    train_df, test_df = pickle.load(f)\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhPqg3gFa1Bj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import pandas\n",
        "\n",
        "# Download and process the dataset files.\n",
        "def download_and_load_datasets(force_download=False):\n",
        "  with open(\"politifactfull.pickle\", 'rb') as f:\n",
        "    train_df, test_df = pickle.load(f)\n",
        "  \n",
        "  return train_df, test_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2abfwdn-g135",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = download_and_load_datasets()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McmUS-FXHW3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwSjjmwJE85q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_COL_1 = ['claim', 'claimtext', 'page', 'body']\n",
        "test = pd.read_csv(\"./stancetask2.csv\", index_col=None, names=_COL_1, sep='\\t')\n",
        "\n",
        "totest = test[395:]\n",
        "\n",
        "print(totest['page'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sb5SvG7FvvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totest['body'] = totest['body'].replace('\\n', '',regex=True).astype(str)\n",
        "totest['body'] = totest['body'].replace('\\d', '',regex=True).astype(str)\n",
        "totest['body'] = totest['body'].replace(' +', ' ',regex=True).astype(str)\n",
        "totest['body'] = totest['body'].replace('\\W+', ' ',regex=True).astype(str)\n",
        "\n",
        "totest['body'] = totest['body'].replace('[^\\u0621-\\u064A\\u0660-\\u0669\\u066E-\\u06D5\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u06F0-\\u06F9a-z-A-Z]+$', '',regex=True).astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akv6x5jkcRZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train['body'] = train['body'].replace('\\n', '',regex=True).astype(str)\n",
        "train['body'] = train['body'].replace('\\d', '',regex=True).astype(str)\n",
        "train['body'] = train['body'].replace(' +', ' ',regex=True).astype(str)\n",
        "train['body'] = train['body'].replace('\\W+', ' ',regex=True).astype(str)\n",
        "\n",
        "test['body'] = test['body'].replace('\\n', '',regex=True).astype(str)\n",
        "test['body'] = test['body'].replace('\\d', '',regex=True).astype(str)\n",
        "test['body'] = test['body'].replace(' +', ' ',regex=True).astype(str)\n",
        "test['body'] = test['body'].replace('\\W+', ' ',regex=True).astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1arYUqERiMyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train= train.replace('[^\\u0621-\\u064A\\u0660-\\u0669\\u066E-\\u06D5\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u06F0-\\u06F9a-z-A-Z]+$', '',regex=True).astype(str)\n",
        "#train['claimtext'] = train['claimtext'].replace('[\\u0621-\\u064A0-9 ]+$', '',regex=True).astype(str)\n",
        "test = test.replace('[^\\u0621-\\u064A\\u0660-\\u0669\\u066E-\\u06D5\\u06EE\\u06EF\\u06FA-\\u06FC\\u06FF\\u06F0-\\u06F9a-z-A-Z]+$', '',regex=True).astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QetC-bOUHkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install googletrans"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IilwjQF8xj_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from googletrans import Translator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeyevCzhT2Rg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#translator = Translator()\n",
        "train['claimtext'] = train['claimtext'].map(lambda x: Translator().translate(text=x, dest='en').text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfnMm83fwWlG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#translator = Translator()\n",
        "test['claimtext'] = test['claimtext'].map(lambda x: Translator().translate(text=x, dest='en').text)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFF9n0mowY3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "\n",
        "translator = Translator()\n",
        "for index_label, row_series in train.iterrows():\n",
        "  # For each row update the 'Bonus' value to it's double\n",
        "  x = row_series['body']\n",
        "  x = x[:2000]\n",
        "  train.at[index_label , 'body'] = Translator().translate(text=x, dest='en').text \n",
        "  #time.sleep(0.1)\n",
        "  \n",
        "for index_label, row_series in test.iterrows():\n",
        "  # For each row update the 'Bonus' value to it's double\n",
        "  x = row_series['body']\n",
        "  x = x[:2000]\n",
        "  test.at[index_label , 'body'] = Translator().translate(text=x, dest='en').text "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1bDca-9P3Hz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"task2treng2000.pickle\", \"wb\") as f:\n",
        "    pickle.dump([train, test], f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lw_F488eixTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train.sample(len(train))\n",
        "test = test.sample(len(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfRnHSz3iSXz",
        "colab_type": "text"
      },
      "source": [
        "For us, our input data is the 'sentence' column and our label is the 'polarity' column (0, 1 for negative and positive, respecitvely)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuMOGwFui4it",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEAD_COLUMN = 'claimtext'\n",
        "BODY_COLUMN = 'body'\n",
        "LABEL_COLUMN = 'label'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [\"-1\",\"0\", \"1\",\"2\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqDvV0IpMEQH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEAD_COLUMN = 'Headline'\n",
        "BODY_COLUMN = 'articleBody'\n",
        "LABEL_COLUMN = 'Stance'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [\"-1\",\"0\", \"1\",\"2\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fWvLBKMVD6m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEAD_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'label'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [\"0\",\"1\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCjq87nTbB4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "HEAD_COLUMN = 'statement'\n",
        "LABEL_COLUMN = 'label'\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n",
        "label_list = [\"true\",\"barely-true\",\"half-true\",\"pants-fire\",\"false\",\"mostly-true\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V399W0rqNJ-Z",
        "colab_type": "text"
      },
      "source": [
        "#Data Preprocessing\n",
        "We'll need to transform our data into a format BERT understands. This involves two steps. First, we create  `InputExample`'s using the constructor provided in the BERT library.\n",
        "\n",
        "- `text_a` is the text we want to classify, which in this case, is the `Request` field in our Dataframe. \n",
        "- `text_b` is used if we're training a model to understand the relationship between sentences (i.e. is `text_b` a translation of `text_a`? Is `text_b` an answer to the question asked by `text_a`?). This doesn't apply to our task, so we can leave `text_b` blank.\n",
        "- `label` is the label for our example, i.e. True, False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9gEt5SmM6i6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[HEAD_COLUMN], \n",
        "                                                                   text_b = x[BODY_COLUMN], \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[HEAD_COLUMN], \n",
        "                                                                   text_b = x[BODY_COLUMN], \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R4jiktIVONc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n",
        "                                                                   text_a = x[HEAD_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[HEAD_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhJSe0QHNG7U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\"\n",
        "#BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_cased_L-24_H-1024_A-16/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL5W8gEGRTAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cYrBD88D3b46"
      },
      "source": [
        "#Creating a model\n",
        "\n",
        "Now that we've prepared our data, let's focus on building a model. `create_model` does just this below. First, it loads the BERT tf hub module again (this time to extract the computation graph). Next, it creates a single new layer that will be trained to adapt BERT to our sentiment task (i.e. classifying whether a movie review is positive or negative). This strategy of using a mostly trained model is called [fine-tuning](http://wiki.fast.ai/index.php/Fine_tuning)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o2a5ZIvRcJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnH-AnOQ9KKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    \n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        " \n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        #f1_score = tf.contrib.metrics.f1_score(\n",
        "            #label_ids,\n",
        "            #predicted_labels)\n",
        "        #auc = tf.metrics.auc(\n",
        "          #   label_ids,\n",
        "           # predicted_labels)\n",
        "        recall = tf.metrics.recall(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        precision = tf.metrics.precision(\n",
        "            label_ids,\n",
        "            predicted_labels) \n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "\n",
        "        #p0 = tf.metrics.precision_at_k(label_ids, predicted_labels, 1, class_id=0)\n",
        "        #p1 = tf.metrics.precision_at_k(label_ids, predicted_labels, 1, class_id=1)\n",
        "        #p2 = tf.metrics.precision_at_k(label_ids, predicted_labels, 1, class_id=2)\n",
        "        #p3 = tf.metrics.precision_at_k(label_ids, predicted_labels, 1, class_id=3)\n",
        "        #p4 = tf.metrics.precision_at_k(label_ids, predicted_labels, 1, class_id=4)\n",
        "        #p5 = tf.metrics.precision_at_k(label_ids, predicted_labels, 1, class_id=5)\n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            #\"f1_score\": f1_score,\n",
        "            #\"auc\": auc,\n",
        "            \"precision\": precision,\n",
        "            \"recall\": recall,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg,\n",
        "            #\"p0\":p0,\n",
        "            #\"p1\":p1,\n",
        "            #\"p2\":p2,\n",
        "            #\"p3\":p3,\n",
        "            #\"p4\":p4,\n",
        "            #\"p5\":p5\n",
        "        }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjwJ4bTeWXD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 1\n",
        "# Warmup is a period of time where hte learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emHf9GhfWBZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1bU0ezW5yu_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_steps = 190\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEJldMr3WYZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_WebpS1X97v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Pv2bAlOX_-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nucD4gluYJmK",
        "colab_type": "code",
        "outputId": "409493f0-6b13-4473-f5ec-10672e497947",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "W0623 18:24:04.432298 139940367767424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0623 18:24:06.919957 139940367767424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1066: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:25:06.317314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIhejfpyJ8Bx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\n",
        "    features=test_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPVEXhNjYXC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsrbTD2EJTVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getPrediction(in_sentences):\n",
        "  labels = [\"-1\", \"0\",\"1\",\"2\"]\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = y, label = \"0\") for x,y in in_sentences] # here, \"\" is just a dummy label\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4JQcFie8XoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = getPrediction(test_df.statement)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndDsCboF0BGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import csv\n",
        "newlist = []\n",
        "cont=0\n",
        "for x in predictions:\n",
        "  x = str(x)\n",
        "  start = x.find('2), ')+5\n",
        "  end = x.find(')', start)-1\n",
        "  newlist.append( int(x[start:end]))\n",
        "\n",
        "cont=395\n",
        "with open('out2B2.tsv', 'w') as f:\n",
        "  writer=csv.writer(f, delimiter='\\t')\n",
        "  for x in newlist:\n",
        "    print('%s\\t%s\\t%s\\t%s' %(totest['claim'][cont], totest['page'][cont],x, \"TheEarthIsFlat2Bext\") )\n",
        "    writer.writerow([totest['claim'][cont], totest['page'][cont],x, \"TheEarthIsFlat2Bext\"])\n",
        "    cont=cont+1"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}